# Лабораторная работа №4  
## Мониторинг ML-сервиса с использованием Prometheus и Grafana

---

## 1. Цель работы

Целью лабораторной работы является разработка и развертывание системы мониторинга
микросервиса машинного обучения с использованием **Prometheus** и **Grafana**.

В ходе работы необходимо:
- запустить ML-сервис предсказаний на FastAPI;
- реализовать сбор метрик (HTTP-запросы, задержки, результаты предсказаний);
- настроить Prometheus для сбора метрик;
- визуализировать метрики в Grafana с помощью dashboard’ов;
- организовать запуск всех компонентов через Docker Compose.

---

## 2. Общая архитектура системы

Система состоит из следующих компонентов:

- **ML Service (FastAPI)**  
  REST API для получения предсказаний и экспорта метрик.

- **Request Generator**  
  Сервис генерации HTTP-запросов для имитации нагрузки.

- **Prometheus**  
  Система сбора и хранения метрик.

- **Grafana**  
  Система визуализации метрик и построения дашбордов.

Все сервисы запускаются в отдельных Docker-контейнерах и объединены в одну сеть с
помощью Docker Compose.

---

## 3. Структура проекта

my_proj/
├── services/
│ ├── ml_service/
│ │ ├── main.py
│ │ ├── Dockerfile
│ │ └── requirements.txt
│ │
│ ├── requests/
│ │ ├── request_generator.py
│ │ ├── Dockerfile
│ │ └── requirements.txt
│ │
│ ├── prometheus/
│ │ └── prometheus.yml
│ │
│ ├── grafana/
│ │
│ └── compose.yml
│
├── README.md
└── requirements.txt
## 4. ML-сервис предсказаний

ML-сервис реализован с использованием **FastAPI** и предоставляет следующие endpoints:

- `GET /` — тестовый endpoint
- `POST /api/prediction` — получение предсказания
- `GET /metrics` — экспорт метрик для Prometheus

### Собираемые метрики:
- количество HTTP-запросов (`http_requests_total`);
- задержка обработки запросов (`http_request_duration_seconds`);
- количество предсказаний (`model_predictions_count`).

---

## 5. Генератор запросов (Request Generator)

Сервис `request_generator` предназначен для имитации нагрузки на ML-сервис.
Он периодически отправляет POST-запросы на endpoint `/api/prediction`,
что позволяет наблюдать изменение метрик в Prometheus и Grafana.

---

## 6. Prometheus

Prometheus используется для:
- периодического опроса endpoint `/metrics`;
- хранения временных рядов метрик.

Конфигурация Prometheus задана в файле `prometheus/prometheus.yml`,
где настроен target для ML-сервиса.

Prometheus доступен по адресу:
http://localhost:9090

yaml
Копировать код

---

## 7. Grafana

Grafana используется для визуализации метрик, полученных из Prometheus.

### Реализованные панели мониторинга:
- **Requests per minute (RPS)** — количество запросов в минуту;
- **Prediction latency** — средняя задержка обработки запросов;
- **Total predictions** — общее количество предсказаний.

Grafana доступна по адресу:
http://localhost:3000

yaml
Копировать код

Данные подключаются через источник данных **Prometheus**.

---

## 8. Запуск проекта

### 8.1 Остановка предыдущих контейнеров
```bash
docker compose down -v
8.2 Сборка и запуск сервисов
bash
Копировать код
docker compose up --build
После запуска становятся доступны:

ML-сервис: http://localhost:8000/docs

Prometheus: http://localhost:9090

Grafana: http://localhost:3000

9. Результаты работы
В ходе лабораторной работы было выполнено:

развертывание ML-сервиса предсказаний;

реализация сбора Prometheus-метрик;

настройка Prometheus для мониторинга сервиса;

визуализация метрик в Grafana;

организация запуска всех компонентов через Docker Compose.

Система успешно демонстрирует мониторинг нагрузки и производительности
микросервиса машинного обучения.
